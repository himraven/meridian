#!/usr/bin/env python3
"""
13F Filings Collector

æ•°æ®æº: SEC EDGAR (å…è´¹)
è¿½è¸ª: Berkshire Hathaway (Buffett), Bridgewater, Renaissance, etc.

13F æŠ«éœ²: å­£åº¦ç»“æŸå 45 å¤©å†…
"""

import json
import requests
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, List, Dict
import xml.etree.ElementTree as ET
import sys

sys.path.append(str(Path(__file__).parent.parent))
from config import DATA_DIR

# è¿½è¸ªçš„æœºæ„ (CIK å·)
TRACKED_FUNDS = {
    "0001067983": {"name": "Berkshire Hathaway", "alias": "Buffett"},
    "0001350694": {"name": "Bridgewater Associates", "alias": "Dalio"},
    "0001037389": {"name": "Renaissance Technologies", "alias": "Simons"},
    "0001423053": {"name": "Citadel Advisors", "alias": "Griffin"},
    "0001336528": {"name": "Pershing Square", "alias": "Ackman"},
    "0001649339": {"name": "Appaloosa Management", "alias": "Tepper"},
    "0001029160": {"name": "Soros Fund Management", "alias": "Soros"},
}

# SEC EDGAR URLs
SEC_BASE = "https://www.sec.gov"
SEC_FILINGS_API = f"{SEC_BASE}/cgi-bin/browse-edgar"
SEC_SUBMISSIONS = "https://data.sec.gov/submissions"


class F13Collector:
    """13F æ–‡ä»¶é‡‡é›†å™¨"""
    
    def __init__(self):
        self.data_dir = DATA_DIR / "13f_filings"
        self.data_dir.mkdir(exist_ok=True)
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "SmartMoneyTracker/1.0 (contact@example.com)",  # SEC requires this
            "Accept-Encoding": "gzip, deflate",
        })
    
    def get_latest_13f(self, cik: str) -> Optional[Dict]:
        """è·å–æœ€æ–°çš„ 13F æäº¤"""
        # ä½¿ç”¨ SEC çš„ submissions API
        url = f"{SEC_SUBMISSIONS}/CIK{cik.zfill(10)}.json"
        
        try:
            resp = self.session.get(url, timeout=30)
            resp.raise_for_status()
            data = resp.json()
            
            # æŸ¥æ‰¾æœ€æ–°çš„ 13F-HR æ–‡ä»¶
            filings = data.get("filings", {}).get("recent", {})
            forms = filings.get("form", [])
            accessions = filings.get("accessionNumber", [])
            filing_dates = filings.get("filingDate", [])
            
            for i, form in enumerate(forms):
                if form in ["13F-HR", "13F-HR/A"]:
                    return {
                        "cik": cik,
                        "form": form,
                        "accession": accessions[i],
                        "filing_date": filing_dates[i],
                        "company": data.get("name", ""),
                    }
            
            return None
            
        except Exception as e:
            print(f"[13F] Error fetching {cik}: {e}")
            return None
    
    def get_13f_holdings(self, cik: str, accession: str) -> List[Dict]:
        """è§£æ 13F æŒä»“æ•°æ®"""
        holdings = []
        
        # æ„å»º holdings XML URL
        accession_clean = accession.replace("-", "")
        url = f"https://www.sec.gov/Archives/edgar/data/{int(cik)}/{accession_clean}"
        
        try:
            # å…ˆè·å–æ–‡ä»¶åˆ—è¡¨æ‰¾åˆ° holdings XML
            index_url = f"{url}/index.json"
            resp = self.session.get(index_url, timeout=30)
            resp.raise_for_status()
            
            files = resp.json().get("directory", {}).get("item", [])
            holdings_file = None
            
            # Strategy: find the XML file that contains the holdings info table
            # Different filers use different naming conventions:
            #   - Most common: "infotable.xml" or "*infotable*.xml"
            #   - Some use: "*holding*.xml"
            #   - Others use numeric names: "46994.xml"
            # We exclude "primary_doc.xml" (the cover page) and index files
            xml_candidates = []
            for f in files:
                name = f.get("name", "")
                name_lower = name.lower()
                if not name_lower.endswith(".xml"):
                    continue
                if name_lower == "primary_doc.xml":
                    continue
                if "index" in name_lower:
                    continue
                # Prefer files with known patterns, but collect all XML candidates
                size = f.get("size", "")
                xml_candidates.append((name, size))
            
            # Pick best candidate: prefer "infotable", then "holding", then largest XML
            for name, size in xml_candidates:
                if "infotable" in name.lower():
                    holdings_file = name
                    break
            
            if not holdings_file:
                for name, size in xml_candidates:
                    if "holding" in name.lower():
                        holdings_file = name
                        break
            
            if not holdings_file and xml_candidates:
                # Fall back to the first non-primary XML (often the only one)
                holdings_file = xml_candidates[0][0]
            
            if not holdings_file:
                print(f"[13F] No holdings file found for {cik}")
                return holdings
            
            # è·å–å¹¶è§£æ holdings XML
            holdings_url = f"{url}/{holdings_file}"
            resp = self.session.get(holdings_url, timeout=30)
            resp.raise_for_status()
            
            # è§£æ XML
            root = ET.fromstring(resp.content)
            ns = {"ns": "http://www.sec.gov/edgar/document/thirteenf/informationtable"}
            
            for info in root.findall(".//ns:infoTable", ns):
                holding = {
                    "issuer": info.findtext("ns:nameOfIssuer", "", ns),
                    "class": info.findtext("ns:titleOfClass", "", ns),
                    "cusip": info.findtext("ns:cusip", "", ns),
                    "value": int(info.findtext("ns:value", "0", ns)) * 1000,  # å•ä½æ˜¯åƒç¾å…ƒ
                    "shares": int(info.findtext(".//ns:sshPrnamt", "0", ns)),
                    "put_call": info.findtext(".//ns:putCall", "", ns),
                }
                holdings.append(holding)
            
            print(f"[13F] Parsed {len(holdings)} holdings from {cik}")
            
        except Exception as e:
            print(f"[13F] Error parsing holdings for {cik}: {e}")
        
        return holdings
    
    def load_previous_filing(self, cik: str) -> Optional[Dict]:
        """åŠ è½½ä¹‹å‰çš„ filing æ•°æ®"""
        filepath = self.data_dir / f"{cik}_latest.json"
        if filepath.exists():
            with open(filepath) as f:
                return json.load(f)
        return None
    
    def save_filing(self, cik: str, data: Dict):
        """ä¿å­˜ filing æ•°æ®"""
        filepath = self.data_dir / f"{cik}_latest.json"
        with open(filepath, "w") as f:
            json.dump(data, f, indent=2)
        
        # ä¿å­˜å†å²ç‰ˆæœ¬
        if data.get("filing_date"):
            history_file = self.data_dir / f"{cik}_{data['filing_date']}.json"
            if not history_file.exists():
                with open(history_file, "w") as f:
                    json.dump(data, f, indent=2)
    
    def detect_changes(self, cik: str, current: Dict, previous: Dict) -> List[Dict]:
        """æ£€æµ‹æŒä»“å˜åŒ–"""
        changes = []
        fund_info = TRACKED_FUNDS.get(cik, {})
        fund_name = fund_info.get("alias", fund_info.get("name", cik))
        
        curr_holdings = {h["cusip"]: h for h in current.get("holdings", [])}
        prev_holdings = {h["cusip"]: h for h in previous.get("holdings", [])}
        
        # æ–°å»ºä»“ä½
        for cusip, h in curr_holdings.items():
            if cusip not in prev_holdings:
                changes.append({
                    "type": "NEW_POSITION",
                    "fund": fund_name,
                    "issuer": h["issuer"],
                    "cusip": cusip,
                    "shares": h["shares"],
                    "value": h["value"],
                })
        
        # æ¸…ä»“
        for cusip, h in prev_holdings.items():
            if cusip not in curr_holdings:
                changes.append({
                    "type": "SOLD_OUT",
                    "fund": fund_name,
                    "issuer": h["issuer"],
                    "cusip": cusip,
                    "prev_shares": h["shares"],
                })
        
        # åŠ ä»“/å‡ä»“ (å˜åŒ–è¶…è¿‡10%)
        for cusip, curr in curr_holdings.items():
            if cusip in prev_holdings:
                prev = prev_holdings[cusip]
                if prev["shares"] > 0:
                    change_pct = (curr["shares"] - prev["shares"]) / prev["shares"] * 100
                    
                    if abs(change_pct) > 10:
                        changes.append({
                            "type": "INCREASED" if change_pct > 0 else "DECREASED",
                            "fund": fund_name,
                            "issuer": curr["issuer"],
                            "cusip": cusip,
                            "prev_shares": prev["shares"],
                            "curr_shares": curr["shares"],
                            "change_pct": change_pct,
                        })
        
        return changes
    
    def run(self) -> List[Dict]:
        """è¿è¡Œé‡‡é›†"""
        print(f"[13F] Starting collection at {datetime.now()}")
        all_changes = []
        
        for cik, info in TRACKED_FUNDS.items():
            print(f"[13F] Checking {info['name']}...")
            
            # è·å–æœ€æ–° filing
            latest = self.get_latest_13f(cik)
            if not latest:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–° filing
            previous = self.load_previous_filing(cik)
            if previous and previous.get("accession") == latest["accession"]:
                print(f"[13F] {info['name']}: No new filing")
                continue
            
            print(f"[13F] {info['name']}: New filing {latest['filing_date']}")
            
            # è·å–æŒä»“æ•°æ®
            holdings = self.get_13f_holdings(cik, latest["accession"])
            latest["holdings"] = holdings
            
            # æ£€æµ‹å˜åŒ–
            if previous:
                changes = self.detect_changes(cik, latest, previous)
                if changes:
                    all_changes.extend(changes)
                    print(f"[13F] {info['name']}: {len(changes)} changes")
            
            # ä¿å­˜
            self.save_filing(cik, latest)
            
            # Dual-write to SQLite
            self._save_to_db(cik, latest, holdings)
        
        print(f"[13F] Done. Total changes: {len(all_changes)}")
        return all_changes
    
    def _save_to_db(self, cik: str, filing: Dict, holdings: list):
        """Write filing to SQLite database (dual-write)."""
        try:
            from api.database import SessionLocal
            from api.crud import upsert_institution_filing, log_refresh
            import time
            db = SessionLocal()
            t0 = time.time()
            info = TRACKED_FUNDS.get(cik, {})
            filing_data = {
                "cik": cik,
                "fund_name": info.get("alias", info.get("name")),
                "company_name": info.get("name"),
                "filing_date": filing.get("filing_date"),
                "quarter": filing.get("quarter"),
                "accession": filing.get("accession"),
                "total_value": sum(h.get("value", 0) for h in holdings),
                "holdings_count": len(holdings),
            }
            count = upsert_institution_filing(db, filing_data, holdings)
            ms = int((time.time() - t0) * 1000)
            log_refresh(db, "13f", "success", count, ms)
            db.close()
            print(f"[13F] SQLite: {cik} â€” {count} holdings written ({ms}ms)")
        except Exception as e:
            print(f"[13F] SQLite write failed (JSON still saved): {e}")


def format_13f_changes(changes: List[Dict]) -> str:
    """æ ¼å¼åŒ– 13F å˜åŒ–ä¸ºæ¶ˆæ¯"""
    if not changes:
        return ""
    
    lines = ["ğŸ“Š **13F å¤§ä½¬æŒä»“å˜åŒ–**\n"]
    
    # æŒ‰åŸºé‡‘åˆ†ç»„
    by_fund = {}
    for c in changes:
        fund = c["fund"]
        if fund not in by_fund:
            by_fund[fund] = []
        by_fund[fund].append(c)
    
    for fund, fund_changes in by_fund.items():
        lines.append(f"**{fund}**")
        
        for c in fund_changes[:10]:
            emoji = {
                "NEW_POSITION": "ğŸŸ¢ æ–°å»ºä»“",
                "SOLD_OUT": "ğŸ”´ æ¸…ä»“",
                "INCREASED": "ğŸ“ˆ åŠ ä»“",
                "DECREASED": "ğŸ“‰ å‡ä»“",
            }.get(c["type"], "â€¢")
            
            if c["type"] == "NEW_POSITION":
                value_m = c.get("value", 0) / 1_000_000
                lines.append(f"  {emoji} {c['issuer']} ${value_m:.1f}M")
            elif c["type"] == "SOLD_OUT":
                lines.append(f"  {emoji} {c['issuer']}")
            else:
                lines.append(f"  {emoji} {c['issuer']} {c.get('change_pct', 0):+.1f}%")
        
        if len(fund_changes) > 10:
            lines.append(f"  ... è¿˜æœ‰ {len(fund_changes)-10} æ¡")
        lines.append("")
    
    return "\n".join(lines)


if __name__ == "__main__":
    collector = F13Collector()
    changes = collector.run()
    
    if changes:
        msg = format_13f_changes(changes)
        print("\n" + "="*50)
        print(msg)
    else:
        print("\n[13F] No new filings or changes detected")
